import pandas as pd
import numpy as np

import matplotlib.pyplot as plt

from tslearn.clustering import TimeSeriesKMeans
from tslearn.preprocessing import TimeSeriesScalerMeanVariance

#CHANGE PATH TO DESIRED CSV FILE
df = pd.read_csv('/home/wendyy/projects/def-sushant/wendyy/mutshape/data/merged_maf/coad3.csv')

interbase_features = ['Shift', 'Slide', 'Rise', 'Tilt', 'Roll', 'HelT']
intrabase_features = ['Shear', 'Stretch', 'Stagger', 'Buckle', 'ProT', 'Opening', 'MGW']

for feature in interbase_features + intrabase_features:
    df[f'{feature}_wt'] = df[f'{feature}_wt'].apply(lambda x: [float(num) for num in x.split()])
    df[f'{feature}_mut'] = df[f'{feature}_mut'].apply(lambda x: [float(num) for num in x.split()])

for feature in interbase_features:
    df[f'{feature}_wt'] = df[f'{feature}_wt'].apply(lambda x: np.insert(x, 10, (x[9] + x[10]) / 2))
    df[f'{feature}_mut'] = df[f'{feature}_mut'].apply(lambda x: np.insert(x, 10, (x[9] + x[10]) / 2))

# Ensure all columns are numpy arrays
for feature in interbase_features + intrabase_features:
    df[f'{feature}_wt'] = df[f'{feature}_wt'].apply(lambda x: np.array([float(num) for num in x.split()]) if isinstance(x, str) else np.array(x))
    df[f'{feature}_mut'] = df[f'{feature}_mut'].apply(lambda x: np.array([float(num) for num in x.split()]) if isinstance(x, str) else np.array(x))

# Calculate delta values using NumPy arrays
for feature in interbase_features + intrabase_features:
    df[f'{feature}_delta'] = df.apply(lambda row: row[f'{feature}_mut'] - row[f'{feature}_wt'], axis=1)

X = np.stack(df[[f'{feature}_delta' for feature in (interbase_features + intrabase_features)]]
             .apply(lambda row: np.column_stack(row.values), axis=1)
             .values)

# Define delta columns
delta_columns = [f'{feature}_delta' for feature in interbase_features + intrabase_features]

# First, remove the first 3 and last 3 values from each delta array (zero padding)
for feature in interbase_features + intrabase_features:
    df[f'{feature}_delta'] = df[f'{feature}_delta'].apply(lambda x: x[5:-5])

# Stack the trimmed delta values into a 3D array (samples x timesteps x features)
X = np.stack(df[delta_columns].apply(lambda row: np.column_stack(row.values), axis=1).values)

# Standardize the time series data
scaler = TimeSeriesScalerMeanVariance()
X_scaled = scaler.fit_transform(X)

max_k = 15
inertias = []

for k in range(2, max_k + 1):
    kmeans = TimeSeriesKMeans(n_clusters=k, metric="euclidean", random_state=42)
    labels = kmeans.fit_predict(X_scaled)
    inertias.append(kmeans.inertia_)

# Plot elbow and silhouette scores
plt.figure(figsize=(12,5))
plt.subplot(1,2,1)
plt.plot(range(2,max_k+1), inertias,'-o')
plt.xlabel('Number of clusters')
plt.ylabel('Inertia')
plt.title('Elbow Plot')

# CHANGE PATH TO YOUR DESIRED OUTPUT DIRECTORY
plt.savefig('/home/wendyy/projects/def-sushant/wendyy/mutshape/exs/kmeans_elbow.png')